[
    {
      "question_ko": "현대 x86 프로세서는 CISC 명령어 집합을 사용하므로, RISC 아키텍처(예: ARM) 기반 프로세서보다 명령어 실행 단계에서 본질적으로 느리다.",
      "question_en": "Since modern x86 processors use the CISC instruction set, they are inherently slower in the instruction execution stage than RISC architecture-based processors (e.g., ARM).",
      "hint_ko": "현대 x86 프로세서가 내부적으로 복잡한 명령어를 어떻게 처리하는지 생각해 보세요.",
      "hint_en": "Consider how modern x86 processors internally handle complex instructions.",
      "topic": "computerArchitecture",
      "difficulty": "medium",
      "concept": "RISC vs CISC Architecture",
      "questionType": "trap",
      "answerOptions": [
        {
          "text_ko": "False",
          "text_en": "False",
          "rationale_ko": "현대 x86 프로세서는 하드웨어 디코더가 CISC 명령어를 RISC와 유사한 단순한 마이크로 연산(micro-ops)으로 변환하여 파이프라인에서 실행하므로, 실행 속도 격차는 미미합니다.",
          "rationale_en": "Modern x86 processors use hardware decoders to translate CISC instructions into simple RISC-like micro-operations (micro-ops) for execution in the pipeline, making the execution speed difference negligible.",
          "isCorrect": true
        },
        {
          "text_ko": "True",
          "text_en": "True",
          "rationale_ko": "CISC 명령어는 가변 길이이고 복잡하지만, 내부적인 변환 과정을 통해 RISC와 유사한 효율성을 달성하므로 본질적으로 느리다는 것은 오해입니다.",
          "rationale_en": "While CISC instructions are variable-length and complex, internal translation achieves RISC-like efficiency, so it is a misconception that they are inherently slower.",
          "isCorrect": false
        }
      ]
    },
    {
      "question_ko": "RISC-V의 `lw x5, 40(x6)` 명령어에서 메모리 주소를 계산하는 방식(Base+Offset)에 대한 설명으로 옳은 것은?",
      "question_en": "Which description is correct regarding the memory address calculation method (Base+Offset) for the RISC-V instruction `lw x5, 40(x6)`?",
      "hint_ko": "베이스 레지스터의 값과 오프셋을 어떻게 조합하나요?",
      "hint_en": "How are the base register value and the offset combined?",
      "topic": "computerArchitecture",
      "difficulty": "easy",
      "concept": "Addressing Modes",
      "questionType": "conceptual",
      "answerOptions": [
        {
          "text_ko": "유효 주소 = 레지스터 x6의 값 + 40",
          "text_en": "Effective Address = Value of register x6 + 40",
          "rationale_ko": "변위 주소 지정(Displacement Addressing) 방식은 베이스 레지스터의 값에 즉시값(오프셋)을 더하여 유효 주소를 생성합니다. 이는 배열이나 구조체 접근에 유용합니다.",
          "rationale_en": "Displacement Addressing generates the effective address by adding an immediate value (offset) to the value of the base register. This is useful for accessing arrays or structures.",
          "isCorrect": true
        },
        {
          "text_ko": "유효 주소 = 레지스터 x6의 값 + 레지스터 x5의 값",
          "text_en": "Effective Address = Value of register x6 + Value of register x5",
          "rationale_ko": "이는 인덱스 주소 지정 방식(Indexed Addressing)에 해당하며, `lw` 명령어 형식과는 다릅니다.",
          "rationale_en": "This corresponds to Indexed Addressing, which differs from the `lw` instruction format.",
          "isCorrect": false
        },
        {
          "text_ko": "유효 주소 = 40 (절대 주소)",
          "text_en": "Effective Address = 40 (Absolute Address)",
          "rationale_ko": "이는 직접 주소 지정(Direct Addressing)이며, 베이스 레지스터를 사용하지 않는 방식입니다.",
          "rationale_en": "This is Direct Addressing, which does not use a base register.",
          "isCorrect": false
        },
        {
          "text_ko": "유효 주소 = 메모리[x6 + 40]의 값",
          "text_en": "Effective Address = Value at Memory[x6 + 40]",
          "rationale_ko": "이는 간접 주소 지정(Indirect Addressing)의 개념으로, 메모리를 두 번 참조하게 됩니다.",
          "rationale_en": "This is the concept of Indirect Addressing, which involves referencing memory twice.",
          "isCorrect": false
        }
      ]
    },
    {
      "question_ko": "함수 호출 규약(Calling Convention)에서 'Caller-saved' 레지스터와 'Callee-saved' 레지스터의 차이점은 무엇인가?",
      "question_en": "What is the difference between 'Caller-saved' and 'Callee-saved' registers in calling conventions?",
      "hint_ko": "누가 레지스터 값을 보존할 책임을 지는지 생각해보세요.",
      "hint_en": "Think about who is responsible for preserving the register values.",
      "topic": "computerArchitecture",
      "difficulty": "medium",
      "concept": "Procedure Calling Convention & Stack Frame",
      "questionType": "comparative",
      "answerOptions": [
        {
          "text_ko": "Caller-saved는 함수 호출 전에 호출자가 저장해야 하며 피호출자가 마음대로 쓸 수 있고, Callee-saved는 피호출자가 사용하려면 원래 값을 저장하고 복원해야 한다.",
          "text_en": "Caller-saved registers must be saved by the caller before the call and can be freely used by the callee; Callee-saved registers must be saved and restored by the callee if used.",
          "rationale_ko": "호출자(Caller)는 함수 호출 후에도 유지되어야 하는 임시 값(t 레지스터 등)을 저장해야 하며, 피호출자(Callee)는 함수 실행 동안 보존되어야 하는 값(s 레지스터, sp, ra 등)을 복원할 책임이 있습니다.",
          "rationale_en": "The Caller must save temporary values (like t-registers) needed after the call, while the Callee is responsible for restoring preserved values (like s-registers, sp, ra) used during execution.",
          "isCorrect": true
        },
        {
          "text_ko": "Caller-saved 레지스터는 스택 포인터(sp)를 포함하고, Callee-saved 레지스터는 매개변수 레지스터(a0-a7)를 포함한다.",
          "text_en": "Caller-saved registers include the stack pointer (sp), and Callee-saved registers include parameter registers (a0-a7).",
          "rationale_ko": "스택 포인터(sp)는 Callee-saved이며, 매개변수 레지스터는 Caller-saved입니다.",
          "rationale_en": "The stack pointer (sp) is Callee-saved, and parameter registers are Caller-saved.",
          "isCorrect": false
        },
        {
          "text_ko": "모든 레지스터는 기본적으로 Callee-saved이므로 호출자는 아무것도 저장할 필요가 없다.",
          "text_en": "All registers are Callee-saved by default, so the caller needs to save nothing.",
          "rationale_ko": "모든 레지스터를 Callee-saved로 하면 함수 진입/종료 시 오버헤드가 과도하게 커집니다.",
          "rationale_en": "Making all registers Callee-saved would create excessive overhead at function entry/exit.",
          "isCorrect": false
        },
        {
          "text_ko": "Caller-saved 레지스터는 힙 영역에 저장되고, Callee-saved 레지스터는 스택 영역에 저장된다.",
          "text_en": "Caller-saved registers are stored in the Heap, and Callee-saved registers are stored in the Stack.",
          "rationale_ko": "레지스터 백업은 일반적으로 모두 스택 프레임에 저장됩니다.",
          "rationale_en": "Register backups are generally stored in the stack frame regardless of type.",
          "isCorrect": false
        }
      ]
    },
    {
      "question_ko": "단일 사이클 데이터패스(Single-Cycle Datapath) 구현에서 클럭 주기(Clock Cycle Time)를 결정하는 요소는?",
      "question_en": "What determines the Clock Cycle Time in a Single-Cycle Datapath implementation?",
      "hint_ko": "한 사이클 안에 모든 작업이 끝나야 한다면, 어떤 명령어를 기준으로 삼아야 할까요?",
      "hint_en": "If all operations must finish in one cycle, which instruction should set the standard?",
      "topic": "computerArchitecture",
      "difficulty": "medium",
      "concept": "Single-Cycle Datapath",
      "questionType": "conceptual",
      "answerOptions": [
        {
          "text_ko": "가장 실행 시간이 긴 명령어(Critical Path)의 지연 시간",
          "text_en": "The delay of the instruction with the longest execution time (Critical Path).",
          "rationale_ko": "단일 사이클에서는 모든 명령어가 한 클럭 안에 완료되어야 하므로, 가장 경로가 긴 명령어(보통 lw: 메모리 접근 2회 + ALU)에 맞춰 클럭 주기를 설정해야 합니다. 이는 성능 저하의 주원인입니다.",
          "rationale_en": "In a single-cycle design, every instruction must complete in one clock. Thus, the cycle time is set by the longest path (usually lw: 2 memory accesses + ALU), which is a major performance drawback.",
          "isCorrect": true
        },
        {
          "text_ko": "모든 명령어들의 평균 실행 시간",
          "text_en": "The average execution time of all instructions.",
          "rationale_ko": "평균 시간에 맞추면 실행 시간이 긴 명령어는 사이클 내에 완료되지 못해 오류가 발생합니다.",
          "rationale_en": "Setting it to the average would cause longer instructions to fail to complete within the cycle, leading to errors.",
          "isCorrect": false
        },
        {
          "text_ko": "가장 자주 실행되는 명령어의 지연 시간",
          "text_en": "The delay of the most frequently executed instruction.",
          "rationale_ko": "빈도와 상관없이 최악의 경우(Worst Case)를 기준으로 해야 동작을 보장할 수 있습니다.",
          "rationale_en": "Correct operation requires designing for the Worst Case, regardless of frequency.",
          "isCorrect": false
        },
        {
          "text_ko": "ALU 연산 시간만 고려한 시간",
          "text_en": "The time considering only ALU operations.",
          "rationale_ko": "메모리 접근 시간과 레지스터 파일 접근 시간도 포함해야 합니다.",
          "rationale_en": "Memory access time and register file access time must also be included.",
          "isCorrect": false
        }
      ]
    },
    {
      "question_ko": "5단계 파이프라인에서 `lw x1, 0(x2)` 명령어 바로 다음에 `add x3, x1, x4` 명령어가 올 때 발생하는 해저드와 해결책은?",
      "question_en": "What hazard occurs when `add x3, x1, x4` immediately follows `lw x1, 0(x2)` in a 5-stage pipeline, and what is the solution?",
      "hint_ko": "`lw`는 데이터를 언제 준비하나요? `add`는 데이터를 언제 필요로 하나요?",
      "hint_en": "When does `lw` have the data ready? When does `add` need the data?",
      "topic": "computerArchitecture",
      "difficulty": "medium",
      "concept": "Data Hazards & Forwarding",
      "questionType": "code_trace",
      "answerOptions": [
        {
          "text_ko": "Load-Use 해저드가 발생하며, 포워딩만으로는 해결할 수 없어 1 사이클 스톨(Stall)이 필요하다.",
          "text_en": "A Load-Use hazard occurs, which cannot be solved by forwarding alone, requiring a 1-cycle stall.",
          "rationale_ko": "`lw`의 데이터는 MEM 단계가 끝나야 준비되지만, `add`는 EX 단계 시작 시점에 데이터가 필요합니다. 시간적으로 뒤로 가는 포워딩은 불가능하므로 파이프라인을 1사이클 멈춰야(bubble) 합니다.",
          "rationale_en": "`lw` data is ready after the MEM stage, but `add` needs it at the start of EX. Backward-in-time forwarding is impossible, so a 1-cycle stall (bubble) is mandatory.",
          "isCorrect": true
        },
        {
          "text_ko": "RAW 해저드가 발생하며, EX/MEM 단계에서 ID/EX 단계로 포워딩하면 스톨 없이 해결된다.",
          "text_en": "A RAW hazard occurs, which is solved without stalls by forwarding from EX/MEM to ID/EX.",
          "rationale_ko": "일반적인 연산(ALU) 간의 의존성은 포워딩으로 해결되지만, 로드 명령어는 데이터 가용 시점이 늦어 포워딩만으로는 부족합니다.",
          "rationale_en": "While standard ALU dependencies are solved by forwarding, load instructions produce data too late for forwarding alone to suffice.",
          "isCorrect": false
        },
        {
          "text_ko": "구조적 해저드가 발생하며, 데이터 메모리와 명령어 메모리를 분리해야 한다.",
          "text_en": "A structural hazard occurs, requiring separation of data memory and instruction memory.",
          "rationale_ko": "이는 하버드 아키텍처로 해결하는 IF와 MEM 단계 충돌 문제이며, 데이터 의존성 문제와는 다릅니다.",
          "rationale_en": "This refers to IF/MEM conflicts solved by Harvard architecture, distinct from data dependency issues.",
          "isCorrect": false
        },
        {
          "text_ko": "WAW 해저드가 발생하며, 레지스터 리네이밍으로 해결한다.",
          "text_en": "A WAW hazard occurs, solved by register renaming.",
          "rationale_ko": "순차 파이프라인에서는 쓰기 순서가 보장되므로 WAW 해저드는 발생하지 않습니다.",
          "rationale_en": "In in-order pipelines, write order is guaranteed, so WAW hazards do not occur.",
          "isCorrect": false
        }
      ]
    },
    {
      "question_ko": "분기 예측(Branch Prediction)에서 '2비트 포화 카운터(2-bit Saturating Counter)'가 '1비트 예측기'보다 루프 실행 시 유리한 점은?",
      "question_en": "What is the advantage of a '2-bit Saturating Counter' over a '1-bit Predictor' in Branch Prediction when executing loops?",
      "hint_ko": "루프가 끝나서 한 번 분기 예측이 틀렸을 때, 1비트 예측기는 다음번에 바로 마음을 바꾸나요?",
      "hint_en": "When a loop exits and the prediction fails once, does the 1-bit predictor immediately change its mind?",
      "topic": "computerArchitecture",
      "difficulty": "medium",
      "concept": "Control Hazards & Branch Prediction",
      "questionType": "comparative",
      "answerOptions": [
        {
          "text_ko": "일시적인 예측 실패(예: 루프 종료)에도 예측 상태를 유지하여, 다음번 루프 실행 시 초기 오예측을 방지한다.",
          "text_en": "It maintains the prediction state despite a temporary miss (e.g., loop exit), preventing initial misprediction in the next loop execution.",
          "rationale_ko": "1비트 예측기는 루프 마지막에 미분기(Not Taken)가 발생하면 바로 상태를 뒤집어, 다음 루프 진입 시(Taken) 또 틀립니다. 2비트 예측기는 한 번의 실패로는 '강한 분기' 상태를 바꾸지 않아 안정적입니다.",
          "rationale_en": "A 1-bit predictor flips immediately on loop exit (Not Taken), failing again on the next entry (Taken). A 2-bit predictor stays in 'Strongly Taken', tolerating one miss.",
          "isCorrect": true
        },
        {
          "text_ko": "분기 패널티를 0으로 만들 수 있다.",
          "text_en": "It can reduce the branch penalty to zero.",
          "rationale_ko": "예측이 맞아도 타겟 주소 계산 등을 위한 기본 패널티나 BTB 지연이 있을 수 있으며, 예측 실패 시 패널티는 여전히 존재합니다.",
          "rationale_en": "Even with correct prediction, basic penalties or BTB delays exist, and misprediction penalties remain.",
          "isCorrect": false
        },
        {
          "text_ko": "하드웨어 구현 비용이 1비트 예측기보다 저렴하다.",
          "text_en": "Hardware implementation cost is lower than a 1-bit predictor.",
          "rationale_ko": "상태 비트가 2배로 필요하므로 비용은 더 듭니다.",
          "rationale_en": "It requires double the state bits, so the cost is higher.",
          "isCorrect": false
        },
        {
          "text_ko": "모든 분기 명령어에 대해 100% 예측 정확도를 보장한다.",
          "text_en": "It guarantees 100% prediction accuracy for all branch instructions.",
          "rationale_ko": "동적 분기 예측도 패턴이 불규칙하면 틀릴 수 있습니다.",
          "rationale_en": "Dynamic prediction can still fail with irregular patterns.",
          "isCorrect": false
        }
      ]
    },
    {
      "question_ko": "평균 메모리 접근 시간(AMAT)을 계산하는 올바른 공식은?",
      "question_en": "What is the correct formula for calculating Average Memory Access Time (AMAT)?",
      "hint_ko": "캐시에서 찾으면 '적중 시간'만 걸리지만, 못 찾으면 '실패율'만큼 '실패 패널티'가 추가됩니다.",
      "hint_en": "If found in cache, it takes 'Hit Time', but if missed, 'Miss Penalty' is added proportional to 'Miss Rate'.",
      "topic": "computerArchitecture",
      "difficulty": "easy",
      "concept": "Cache Basics: Hits, Misses & Performance",
      "questionType": "conceptual",
      "answerOptions": [
        {
          "text_ko": "AMAT = Hit Time + (Miss Rate × Miss Penalty)",
          "text_en": "AMAT = Hit Time + (Miss Rate × Miss Penalty)",
          "rationale_ko": "모든 접근은 기본적으로 캐시를 확인(Hit Time)하며, 미스가 발생할 확률(Miss Rate)만큼 추가적인 시간(Miss Penalty)이 소요됩니다.",
          "rationale_en": "Every access incurs the Hit Time to check the cache, plus additional time (Miss Penalty) proportional to the probability of a miss (Miss Rate).",
          "isCorrect": true
        },
        {
          "text_ko": "AMAT = (Hit Rate × Hit Time) + (Miss Rate × Miss Penalty)",
          "text_en": "AMAT = (Hit Rate × Hit Time) + (Miss Rate × Miss Penalty)",
          "rationale_ko": "이 식은 Hit Time을 Hit Rate만큼만 반영하는 오류가 있습니다. Hit Time은 Miss인 경우에도(캐시 확인을 위해) 항상 발생합니다.",
          "rationale_en": "This formula incorrectly applies Hit Time only on hits. Hit Time is incurred even on misses (to check the cache).",
          "isCorrect": false
        },
        {
          "text_ko": "AMAT = Hit Time × Miss Rate × Miss Penalty",
          "text_en": "AMAT = Hit Time × Miss Rate × Miss Penalty",
          "rationale_ko": "덧셈이 아닌 곱셈으로 연결된 잘못된 식입니다.",
          "rationale_en": "Incorrect formula using multiplication instead of addition.",
          "isCorrect": false
        },
        {
          "text_ko": "AMAT = Miss Penalty / Hit Rate",
          "text_en": "AMAT = Miss Penalty / Hit Rate",
          "rationale_ko": "단위와 개념이 맞지 않는 식입니다.",
          "rationale_en": "Dimensionally and conceptually incorrect.",
          "isCorrect": false
        }
      ]
    },
    {
      "question_ko": "캐시의 연관도(Associativity)를 높일 때(예: 직접 매핑 -> 4-way 집합 연관) 발생하는 트레이드오프에 대한 설명으로 옳은 것은?",
      "question_en": "Which statement correctly describes the tradeoff when increasing cache Associativity (e.g., Direct Mapped -> 4-way Set Associative)?",
      "hint_ko": "충돌은 줄어들지만, 데이터를 찾을 때 검사해야 할 곳이 많아집니다.",
      "hint_en": "Collisions decrease, but there are more places to check when finding data.",
      "topic": "computerArchitecture",
      "difficulty": "medium",
      "concept": "Cache Mapping: Direct-Mapped, Set-Associative, Fully Associative",
      "questionType": "comparative",
      "answerOptions": [
        {
          "text_ko": "충돌 미스(Conflict Miss)는 감소하지만, 적중 시간(Hit Time)이 증가하고 하드웨어 복잡도가 높아진다.",
          "text_en": "Conflict Misses decrease, but Hit Time increases and hardware complexity rises.",
          "rationale_ko": "연관도가 높으면 데이터가 들어갈 수 있는 위치가 유연해져 충돌이 줄지만, 여러 곳을 동시에 비교(MUX 및 비교기)해야 하므로 회로 지연시간과 비용이 늘어납니다.",
          "rationale_en": "Higher associativity offers flexible placement, reducing conflicts, but requires simultaneous comparisons (MUX & comparators), increasing circuit delay and cost.",
          "isCorrect": true
        },
        {
          "text_ko": "강제 미스(Compulsory Miss)가 감소하고 캐시 용량이 늘어난다.",
          "text_en": "Compulsory Misses decrease and cache capacity increases.",
          "rationale_ko": "연관도는 강제 미스나 전체 용량과는 무관합니다.",
          "rationale_en": "Associativity is unrelated to compulsory misses or total capacity.",
          "isCorrect": false
        },
        {
          "text_ko": "적중 시간(Hit Time)은 감소하지만 미스 패널티(Miss Penalty)가 증가한다.",
          "text_en": "Hit Time decreases, but Miss Penalty increases.",
          "rationale_ko": "비교 로직이 복잡해져 적중 시간은 오히려 증가합니다.",
          "rationale_en": "Hit Time actually increases due to complex comparison logic.",
          "isCorrect": false
        },
        {
          "text_ko": "모든 종류의 미스(Miss)가 감소하여 항상 성능이 향상된다.",
          "text_en": "All types of Misses decrease, always improving performance.",
          "rationale_ko": "Hit Time 증가로 인해 전체 AMAT가 나빠질 수도 있습니다.",
          "rationale_en": "Increased Hit Time can degrade overall AMAT.",
          "isCorrect": false
        }
      ]
    },
    {
      "question_ko": "가상 메모리 시스템에서 TLB 미스(Miss)와 캐시 미스(Miss)의 관계에 대한 설명 중 옳은 것은?",
      "question_en": "Which statement is correct regarding the relationship between TLB Miss and Cache Miss in a virtual memory system?",
      "hint_ko": "주소를 번역하지 못했다고 해서 데이터가 캐시에 없는 것은 아닙니다. (물론 물리 주소를 모르면 캐시를 못 찾을 수는 있지만)",
      "hint_en": "Just because you can't translate the address doesn't mean the data isn't in the cache. (Though you can't find it without the physical address)",
      "topic": "computerArchitecture",
      "difficulty": "hard",
      "concept": "Virtual Memory & Page Table (Architecture Perspective)",
      "questionType": "trap",
      "answerOptions": [
        {
          "text_ko": "TLB 미스와 캐시 미스는 독립적인 사건이며, TLB 미스 후에도 캐시 적중(Hit)이 발생할 수 있다.",
          "text_en": "TLB Miss and Cache Miss are independent events, and a Cache Hit can occur even after a TLB Miss.",
          "rationale_ko": "TLB에 변환 정보가 없더라도(TLB Miss), 페이지 테이블을 통해 물리 주소를 알아낸 후 캐시에 접근했을 때 데이터가 이미 존재(Cache Hit)할 수 있습니다. 반대 경우도 가능합니다.",
          "rationale_en": "Even if translation info is missing in TLB (TLB Miss), once the physical address is retrieved via page table walk, the data might already exist in the cache (Cache Hit). The reverse is also true.",
          "isCorrect": true
        },
        {
          "text_ko": "TLB 미스가 발생하면 반드시 캐시 미스도 발생한다.",
          "text_en": "A TLB Miss always results in a Cache Miss.",
          "rationale_ko": "주소 변환 정보와 실제 데이터의 캐싱 여부는 별개입니다. 흔한 오개념입니다.",
          "rationale_en": "Address translation caching and data caching are separate. This is a common misconception.",
          "isCorrect": false
        },
        {
          "text_ko": "캐시 적중(Hit)이 발생하려면 반드시 TLB 적중(Hit)이 선행되어야 한다.",
          "text_en": "A Cache Hit requires a preceding TLB Hit.",
          "rationale_ko": "VIPT(Virtually Indexed Physically Tagged) 등에서는 동시에 접근하거나, TLB Miss 처리 후 캐시 Hit이 될 수 있습니다.",
          "rationale_en": "With VIPT or after handling a TLB miss, a cache hit is possible without an initial TLB hit.",
          "isCorrect": false
        },
        {
          "text_ko": "페이지 폴트(Page Fault)가 발생해도 TLB 적중(Hit)은 발생할 수 있다.",
          "text_en": "A TLB Hit can occur even if a Page Fault happens.",
          "rationale_ko": "페이지 폴트는 해당 페이지가 메모리에 없다는 뜻이므로, TLB(유효한 변환 정보 캐시)에 해당 정보가 있을 수 없습니다(TLB에는 Valid 페이지만 존재).",
          "rationale_en": "A Page Fault means the page is not in memory, so the TLB (which caches valid translations) cannot contain it.",
          "isCorrect": false
        }
      ]
    },
    {
      "question_ko": "IEEE 754 부동소수점 덧셈 연산에서 결합법칙 `(A + B) + C = A + (B + C)`가 항상 성립하지 않는 이유는?",
      "question_en": "Why does the associative property `(A + B) + C = A + (B + C)` not always hold in IEEE 754 floating-point addition?",
      "hint_ko": "아주 큰 수와 아주 작은 수를 더할 때 작은 수가 어떻게 되는지 생각해 보세요.",
      "hint_en": "Think about what happens to a very small number when added to a very large number.",
      "topic": "computerArchitecture",
      "difficulty": "medium",
      "concept": "IEEE 754 Floating Point",
      "questionType": "trap",
      "answerOptions": [
        {
          "text_ko": "유한한 정밀도로 인한 반올림(Rounding) 오차 때문에, 큰 수와 작은 수를 더할 때 정보 소실이 발생하기 때문이다.",
          "text_en": "Due to rounding errors from finite precision, information loss occurs when adding large and small numbers.",
          "rationale_ko": "예를 들어 (10^30 + -10^30) + 1 = 1 이지만, 10^30 + (-10^30 + 1) 은 가수부 비트 부족으로 1이 흡수되어 0이 될 수 있습니다.",
          "rationale_en": "For example, (10^30 + -10^30) + 1 = 1, but 10^30 + (-10^30 + 1) might result in 0 because the small 1 is absorbed due to limited mantissa bits.",
          "isCorrect": true
        },
        {
          "text_ko": "부동소수점 덧셈은 하드웨어에서 순차적으로 처리되지 않기 때문이다.",
          "text_en": "Because floating-point addition is not processed sequentially in hardware.",
          "rationale_ko": "연산 순서가 아니라 정밀도 한계가 원인입니다.",
          "rationale_en": "The cause is precision limit, not execution order.",
          "isCorrect": false
        },
        {
          "text_ko": "오버플로우가 발생하면 결과가 0으로 초기화되기 때문이다.",
          "text_en": "Because results are reset to 0 upon overflow.",
          "rationale_ko": "오버플로우 시에는 무한대(Infinity)가 됩니다.",
          "rationale_en": "Overflow results in Infinity.",
          "isCorrect": false
        },
        {
          "text_ko": "NaN(Not a Number) 값이 연산 중간에 생성되기 때문이다.",
          "text_en": "Because NaN (Not a Number) values are generated during intermediate steps.",
          "rationale_ko": "NaN 없이도 정밀도 문제로 결합법칙은 깨집니다.",
          "rationale_en": "Associativity breaks due to precision even without NaN.",
          "isCorrect": false
        }
      ]
    },
    {
      "question_ko": "Tomasulo 알고리즘에서 '레지스터 리네이밍(Register Renaming)'을 통해 해결하고자 하는 해저드는?",
      "question_en": "Which hazards does 'Register Renaming' aim to resolve in Tomasulo's Algorithm?",
      "hint_ko": "데이터가 흐르는 '진짜' 의존성이 아니라, 이름만 같아서 생기는 '가짜' 의존성을 찾아보세요.",
      "hint_en": "Look for 'false' dependencies caused by reusing names, not 'true' data flow dependencies.",
      "topic": "computerArchitecture",
      "difficulty": "medium",
      "concept": "Out-of-Order Execution & Tomasulo's Algorithm",
      "questionType": "conceptual",
      "answerOptions": [
        {
          "text_ko": "WAW(Write After Write) 및 WAR(Write After Read) 해저드",
          "text_en": "WAW (Write After Write) and WAR (Write After Read) hazards",
          "rationale_ko": "이들은 레지스터 이름 재사용으로 인한 가짜 의존성(Name Dependence)입니다. 리네이밍을 통해 물리적으로 다른 저장소를 할당하면 병렬 실행이 가능해집니다. RAW는 진짜 의존성이므로 리네이밍으로 제거되지 않습니다.",
          "rationale_en": "These are false dependencies (Name Dependence) due to register reuse. Renaming maps them to different physical locations, enabling parallel execution. RAW is a true dependency and cannot be removed.",
          "isCorrect": true
        },
        {
          "text_ko": "RAW(Read After Write) 해저드",
          "text_en": "RAW (Read After Write) hazard",
          "rationale_ko": "RAW는 데이터 흐름상 필연적인 의존성이므로 제거할 수 없고, 기다려야(Stall/Forwarding) 합니다.",
          "rationale_en": "RAW is an inherent data flow dependency; it must be respected via stalls or forwarding.",
          "isCorrect": false
        },
        {
          "text_ko": "구조적 해저드(Structural Hazard)",
          "text_en": "Structural Hazard",
          "rationale_ko": "구조적 해저드는 하드웨어 자원 부족 문제이며 리네이밍과는 무관합니다.",
          "rationale_en": "Structural hazards concern hardware resource limits, unrelated to renaming.",
          "isCorrect": false
        },
        {
          "text_ko": "제어 해저드(Control Hazard)",
          "text_en": "Control Hazard",
          "rationale_ko": "제어 해저드는 분기 예측으로 해결합니다.",
          "rationale_en": "Control hazards are addressed by branch prediction.",
          "isCorrect": false
        }
      ]
    },
    {
      "question_ko": "암달의 법칙(Amdahl's Law)에 따르면, 전체 프로그램의 80%만 병렬화 가능할 때 프로세서를 무한히 늘렸을 때 얻을 수 있는 최대 속도 향상(Speedup)은?",
      "question_en": "According to Amdahl's Law, if only 80% of a program is parallelizable, what is the maximum Speedup achievable with infinite processors?",
      "hint_ko": "병렬화 불가능한 20%(0.2)는 아무리 프로세서가 많아도 시간을 줄일 수 없습니다.",
      "hint_en": "The non-parallelizable 20% (0.2) cannot be sped up regardless of the number of processors.",
      "topic": "computerArchitecture",
      "difficulty": "medium",
      "concept": "Amdahl's Law & Performance Metrics",
      "questionType": "code_trace",
      "answerOptions": [
        {
          "text_ko": "5배",
          "text_en": "5x",
          "rationale_ko": "Speedup = 1 / ((1-f) + f/N). N이 무한대로 가면 f/N은 0이 되고, 1/(1-0.8) = 1/0.2 = 5가 됩니다. 순차 실행 부분(20%)이 성능의 병목이 됩니다.",
          "rationale_en": "Speedup = 1 / ((1-f) + f/N). As N approaches infinity, f/N becomes 0, leaving 1/(1-0.8) = 1/0.2 = 5. The sequential part (20%) becomes the bottleneck.",
          "isCorrect": true
        },
        {
          "text_ko": "4배",
          "text_en": "4x",
          "rationale_ko": "계산 오류입니다.",
          "rationale_en": "Calculation error.",
          "isCorrect": false
        },
        {
          "text_ko": "20배",
          "text_en": "20x",
          "rationale_ko": "순차 부분을 고려하지 않은 잘못된 추론입니다.",
          "rationale_en": "Incorrect reasoning ignoring the sequential part.",
          "isCorrect": false
        },
        {
          "text_ko": "80배",
          "text_en": "80x",
          "rationale_ko": "병렬화 비율을 그대로 답으로 오인한 경우입니다.",
          "rationale_en": "Mistaking the parallelization ratio for the answer.",
          "isCorrect": false
        }
      ]
    },
    {
      "question_ko": "캐시 일관성 프로토콜(MESI)에서 'Write-Back' 캐시를 사용하는 멀티코어 시스템에 스누핑(Snooping)이 필요한 근본적인 이유는?",
      "question_en": "What is the fundamental reason Snooping is required in a multi-core system using 'Write-Back' caches for cache coherence (MESI)?",
      "hint_ko": "Write-Back은 메모리에 바로 쓰지 않고 캐시에만 최신 값을 가집니다. 다른 코어가 그 주소를 읽으려 하면 어떻게 해야 할까요?",
      "hint_en": "Write-Back keeps the latest value in the cache, not memory. What if another core tries to read that address?",
      "topic": "computerArchitecture",
      "difficulty": "medium",
      "concept": "Cache Coherence Protocols (MESI, Snooping)",
      "questionType": "conceptual",
      "answerOptions": [
        {
          "text_ko": "최신 데이터가 특정 코어의 캐시에만 있고 메모리에는 없을 수 있으므로, 다른 코어의 요청을 감지하여 최신 값을 제공해야 하기 때문이다.",
          "text_en": "Because the latest data might exist only in a specific core's cache and not in memory, so requests from other cores must be detected to provide the fresh value.",
          "rationale_ko": "Write-Back은 수정된 데이터(Dirty)를 캐시에만 보관합니다. 다른 코어가 해당 주소를 요청할 때 스누핑을 통해 이를 감지하고 메모리 읽기를 가로채거나 데이터를 보내주지 않으면, 다른 코어는 메모리의 낡은(Stale) 데이터를 읽게 됩니다.",
          "rationale_en": "Write-Back keeps modified (Dirty) data only in the cache. Without snooping to intercept requests, other cores would read stale data from memory.",
          "isCorrect": true
        },
        {
          "text_ko": "모든 코어가 항상 메모리에 직접 쓰도록 강제하기 위해서이다.",
          "text_en": "To force all cores to always write directly to memory.",
          "rationale_ko": "이는 Write-Through 방식에 대한 설명이며, Write-Back의 장점을 없애는 것입니다.",
          "rationale_en": "This describes Write-Through, defeating the purpose of Write-Back.",
          "isCorrect": false
        },
        {
          "text_ko": "L1 캐시와 L2 캐시 사이의 속도 차이를 줄이기 위해서이다.",
          "text_en": "To reduce the speed gap between L1 and L2 caches.",
          "rationale_ko": "일관성 프로토콜은 속도 차이가 아니라 데이터 무결성 보장을 위한 것입니다.",
          "rationale_en": "Coherence protocols are for data integrity, not speed matching.",
          "isCorrect": false
        },
        {
          "text_ko": "캐시 미스(Cache Miss)를 줄이기 위해서이다.",
          "text_en": "To reduce Cache Misses.",
          "rationale_ko": "오히려 일관성 유지를 위한 무효화(Invalidation) 트래픽으로 인해 미스가 늘어날 수 있습니다(Coherence Miss).",
          "rationale_en": "Actually, invalidation traffic for coherence can increase misses (Coherence Miss).",
          "isCorrect": false
        }
      ]
    },
    {
      "question_ko": "CPU의 전력 소모 공식 `P = α * C * V^2 * f` 에서 전압(V)을 줄이는 것이 주파수(f)를 줄이는 것보다 전력 절감 효과가 큰 이유는?",
      "question_en": "In the CPU power consumption formula `P = α * C * V^2 * f`, why does reducing Voltage (V) yield greater power savings than reducing Frequency (f)?",
      "hint_ko": "수식에서 변수의 차수(지수)를 확인해 보세요.",
      "hint_en": "Check the exponent of the variables in the formula.",
      "topic": "computerArchitecture",
      "difficulty": "easy",
      "concept": "Power Consumption & Energy Efficiency",
      "questionType": "code_trace",
      "answerOptions": [
        {
          "text_ko": "전력은 전압의 제곱에 비례하기 때문에, 전압 감소 시 전력이 비선형적으로(더 급격히) 감소한다.",
          "text_en": "Since power is proportional to the square of the voltage, reducing voltage causes a non-linear (more rapid) decrease in power.",
          "rationale_ko": "주파수(f)는 1차 비례하지만 전압(V)은 2차 비례(V^2)하므로, 전압을 조금만 낮춰도 전력 소모는 크게 줄어듭니다. 이것이 DVFS의 핵심 원리입니다.",
          "rationale_en": "Frequency (f) is linearly proportional, but voltage (V) is quadratically proportional (V^2), so a small drop in voltage significantly cuts power. This is key to DVFS.",
          "isCorrect": true
        },
        {
          "text_ko": "전압을 줄이면 정적 전력(누설 전류)이 0이 되기 때문이다.",
          "text_en": "Because reducing voltage reduces static power (leakage current) to zero.",
          "rationale_ko": "전압을 낮추면 누설 전류도 줄지만 0이 되지는 않습니다. 위 공식은 동적 전력에 대한 것입니다.",
          "rationale_en": "Lower voltage reduces leakage, but not to zero. The formula refers to dynamic power.",
          "isCorrect": false
        },
        {
          "text_ko": "주파수를 줄이면 실행 시간이 늘어나 전체 에너지 소모는 변하지 않기 때문이다.",
          "text_en": "Because reducing frequency increases execution time, leaving total energy consumption unchanged.",
          "rationale_ko": "주파수만 줄이면 에너지는 비슷할 수 있지만, '전력(Power, 단위 시간당 에너지)' 감소 효과 자체를 묻는 질문에서는 차수가 중요합니다.",
          "rationale_en": "While energy might remain similar if only frequency drops, the question asks about 'Power' reduction, where the exponent matters.",
          "isCorrect": false
        },
        {
          "text_ko": "전압과 주파수는 서로 독립적이어서 전압만 따로 줄일 수 있기 때문이다.",
          "text_en": "Because voltage and frequency are independent, so voltage can be reduced alone.",
          "rationale_ko": "실제로는 주파수를 유지한 채 전압만 낮추면 회로가 오동작합니다. (전압을 낮추려면 주파수도 낮춰야 함)",
          "rationale_en": "In reality, lowering voltage without lowering frequency causes malfunction.",
          "isCorrect": false
        }
      ]
    },
    {
      "question_ko": "메모리 맵 입출력(Memory-Mapped I/O) 방식의 특징으로 옳은 것은?",
      "question_en": "Which characteristic correctly describes Memory-Mapped I/O?",
      "hint_ko": "I/O 장치에 접근하기 위해 별도의 명령어(`in`, `out`)가 필요한가요, 아니면 일반 메모리 명령어(`load`, `store`)를 쓰나요?",
      "hint_en": "Does accessing I/O devices require special instructions (`in`, `out`) or standard memory instructions (`load`, `store`)?",
      "topic": "computerArchitecture",
      "difficulty": "medium",
      "concept": "I/O Interface: Polling, Interrupt, DMA (Architecture Perspective)",
      "questionType": "comparative",
      "answerOptions": [
        {
          "text_ko": "I/O 장치 레지스터가 메모리 주소 공간의 일부에 매핑되어, 표준 메모리 접근 명령어(Load/Store)로 I/O를 제어한다.",
          "text_en": "I/O device registers are mapped to part of the memory address space, allowing I/O control via standard memory access instructions (Load/Store).",
          "rationale_ko": "별도의 I/O 명령어가 필요 없어 컴파일러가 최적화하기 쉽고, 메모리 보호 메커니즘을 I/O에도 그대로 적용할 수 있는 장점이 있습니다. (ARM, RISC-V 등에서 주로 사용)",
          "rationale_en": "No special I/O instructions are needed, simplifying compiler optimization and allowing memory protection mechanisms to apply to I/O. (Common in ARM, RISC-V).",
          "isCorrect": true
        },
        {
          "text_ko": "별도의 I/O 명령어(IN, OUT 등)를 사용하여 I/O 주소 공간에 접근한다.",
          "text_en": "It uses separate I/O instructions (IN, OUT, etc.) to access the I/O address space.",
          "rationale_ko": "이는 포트 맵 입출력(Port-Mapped I/O) 또는 격리형 I/O(Isolated I/O) 방식입니다. (x86에서 주로 사용)",
          "rationale_en": "This describes Port-Mapped I/O or Isolated I/O (common in x86).",
          "isCorrect": false
        },
        {
          "text_ko": "I/O 장치가 메인 메모리의 데이터를 직접 가져가므로 CPU가 전혀 개입하지 않는다.",
          "text_en": "The I/O device takes data directly from main memory, so the CPU is not involved at all.",
          "rationale_ko": "이는 DMA(Direct Memory Access)에 대한 설명입니다.",
          "rationale_en": "This describes DMA (Direct Memory Access).",
          "isCorrect": false
        },
        {
          "text_ko": "메모리 주소 공간을 절약하기 위해 I/O 주소를 별도로 관리한다.",
          "text_en": "It manages I/O addresses separately to save memory address space.",
          "rationale_ko": "메모리 맵 I/O는 주소 공간의 일부를 I/O에 할애하므로 주소 공간을 소비합니다.",
          "rationale_en": "Memory-Mapped I/O consumes part of the address space for I/O.",
          "isCorrect": false
        }
      ]
    }
  ]